import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import f1_score
from sklearn.utils import resample
from xgboost import XGBClassifier

# 1. ë°ì´í„° ë¡œë“œ
real_set = pd.read_csv("./_data/preprocessed_data.csv")
fake_set = pd.read_csv("./_data/augmented_dataset_10000_score_91_5.csv")

X = real_set.drop('Attrition', axis=1)
y = real_set['Attrition']

# í…ŒìŠ¤íŠ¸í•  ë¹„ìœ¨ ë¦¬ìŠ¤íŠ¸ (1:0.2ë¶€í„° 1:1.0ê¹Œì§€)
ratios = np.arange(0.2, 0.99, 0.03)
results = []

skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

print("ðŸš€ ë¹„ìœ¨ë³„ ì„±ëŠ¥ ìµœì í™” ì‹¤í—˜ ì‹œìž‘\n")

for ratio in ratios:
    fold_f1 = []
    
    for train_index, val_index in skf.split(X, y):
        # í´ë“œ ë¶„ë¦¬
        X_train_real, X_val = X.iloc[train_index], X.iloc[val_index]
        y_train_real, y_val = y.iloc[train_index], y.iloc[val_index]
        
        # ì‹¤ì œ ë°ì´í„° í´ëž˜ìŠ¤ ë¶„ë¦¬
        train_0 = X_train_real[y_train_real == 0]
        train_1_real = X_train_real[y_train_real == 1]
        
        # ê°€ì§œ ë°ì´í„°ì—ì„œ í‡´ì‚¬ìžë§Œ ë¶„ë¦¬
        train_1_fake = fake_set[fake_set['Attrition'] == 1].drop('Attrition', axis=1)
        
        # [í•µì‹¬] ëª©í‘œ í‡´ì‚¬ìž ìˆ˜ ê³„ì‚° ë° ë¶€ì¡±ë¶„ ì±„ìš°ê¸°
        target_total_1 = int(len(train_0) * ratio)
        needed_n = target_total_1 - len(train_1_real)
        
        if needed_n > 0:
            # ë¶€ì¡±í•œ ë§Œí¼ ê°€ì§œ ë°ì´í„°ì—ì„œ ìƒ˜í”Œë§ (ë³€ìˆ˜ëª… í†µì¼: needed_n)
            train_1_augmented = resample(train_1_fake, n_samples=needed_n, replace=False, random_state=42)
            X_train_combined = pd.concat([train_0, train_1_real, train_1_augmented])
            # yê°’ ìƒì„±: ìž¬ì§ìž(0) ìˆ˜ë§Œí¼ 0, í‡´ì‚¬ìž(1) ì´í•©ë§Œí¼ 1
            y_train_combined = [0] * len(train_0) + [1] * (len(train_1_real) + len(train_1_augmented))
        else:
            X_train_combined = pd.concat([train_0, train_1_real])
            y_train_combined = [0] * len(train_0) + [1] * len(train_1_real)
            
        # ëª¨ë¸ í•™ìŠµ (XGBoost)
        model = XGBClassifier(
            n_estimators=200, 
            learning_rate=0.05, 
            max_depth=5, 
            random_state=42, 
            eval_metric='logloss'
        )
        model.fit(X_train_combined, y_train_combined)
        
        # í‰ê°€
        preds = model.predict(X_val)
        fold_f1.append(f1_score(y_val, preds))
        
    avg_score = np.mean(fold_f1)
    results.append(avg_score)
    print(f"âœ… Ratio 1:{ratio:.1f} -> Avg F1-Score: {avg_score:.4f}")

# 2. ê²°ê³¼ ì‹œê°í™”
plt.figure(figsize=(10, 6))
plt.plot(ratios, results, marker='o', linestyle='-', color='b', linewidth=2)
plt.title('Mixing Ratio vs Attrition F1-Score (5-Fold Avg)', fontsize=14)
plt.xlabel('Synthetic Attrition Ratio (1:X)', fontsize=12)
plt.ylabel('Average F1-Score', fontsize=12)
plt.xticks(ratios)
plt.grid(True, linestyle='--', alpha=0.7)
plt.show()
#  ë¹„ìœ¨ë³„ ì„±ëŠ¥ ìµœì í™” ì‹¤í—˜ ì‹œìž‘

# âœ… Ratio 1:0.2 -> Avg F1-Score: 0.4394
# âœ… Ratio 1:0.2 -> Avg F1-Score: 0.4618
# âœ… Ratio 1:0.3 -> Avg F1-Score: 0.4855
# âœ… Ratio 1:0.3 -> Avg F1-Score: 0.5005
# âœ… Ratio 1:0.3 -> Avg F1-Score: 0.4936
# âœ… Ratio 1:0.3 -> Avg F1-Score: 0.4909
# âœ… Ratio 1:0.4 -> Avg F1-Score: 0.4936
# âœ… Ratio 1:0.4 -> Avg F1-Score: 0.5066
# âœ… Ratio 1:0.4 -> Avg F1-Score: 0.4972
# âœ… Ratio 1:0.5 -> Avg F1-Score: 0.5080
# âœ… Ratio 1:0.5 -> Avg F1-Score: 0.4960
# âœ… Ratio 1:0.5 -> Avg F1-Score: 0.5034
# âœ… Ratio 1:0.6 -> Avg F1-Score: 0.5213
# âœ… Ratio 1:0.6 -> Avg F1-Score: 0.5299
# âœ… Ratio 1:0.6 -> Avg F1-Score: 0.5040
# âœ… Ratio 1:0.6 -> Avg F1-Score: 0.5375
# âœ… Ratio 1:0.7 -> Avg F1-Score: 0.5239
# âœ… Ratio 1:0.7 -> Avg F1-Score: 0.5335
# âœ… Ratio 1:0.7 -> Avg F1-Score: 0.5260
# âœ… Ratio 1:0.8 -> Avg F1-Score: 0.5373
# âœ… Ratio 1:0.8 -> Avg F1-Score: 0.5195
# âœ… Ratio 1:0.8 -> Avg F1-Score: 0.5365
# âœ… Ratio 1:0.9 -> Avg F1-Score: 0.5183
# âœ… Ratio 1:0.9 -> Avg F1-Score: 0.5275
# âœ… Ratio 1:0.9 -> Avg F1-Score: 0.5196
# âœ… Ratio 1:0.9 -> Avg F1-Score: 0.5111
# âœ… Ratio 1:1.0 -> Avg F1-Score: 0.5183